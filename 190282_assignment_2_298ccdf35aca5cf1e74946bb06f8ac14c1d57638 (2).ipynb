{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport time\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom datetime import datetime\nfrom itertools import chain #used for flattening the list of list\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-11T17:58:44.089212Z","iopub.execute_input":"2022-03-11T17:58:44.089715Z","iopub.status.idle":"2022-03-11T17:58:49.729049Z","shell.execute_reply.started":"2022-03-11T17:58:44.089674Z","shell.execute_reply":"2022-03-11T17:58:49.728259Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**part 1**","metadata":{}},{"cell_type":"code","source":"data_f = pd.read_csv('../input/tmd-datasetcleaned/cleaned.csv')\ndata_f.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:58:49.730788Z","iopub.execute_input":"2022-03-11T17:58:49.731073Z","iopub.status.idle":"2022-03-11T17:59:04.741055Z","shell.execute_reply.started":"2022-03-11T17:58:49.731025Z","shell.execute_reply":"2022-03-11T17:59:04.740177Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**part-a**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(\"No_of_Rows: \",data_f.shape[0])\nprint(\"No_of_Columns: \", data_f.shape[1])\nprint(\"Columns: \",data_f.columns)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:59:04.742036Z","iopub.execute_input":"2022-03-11T17:59:04.742253Z","iopub.status.idle":"2022-03-11T17:59:04.748645Z","shell.execute_reply.started":"2022-03-11T17:59:04.742221Z","shell.execute_reply":"2022-03-11T17:59:04.747751Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**part-b**","metadata":{}},{"cell_type":"code","source":"users = data_f[\"user\"].unique()\nprint(\"No_of_Unique_Users: \", len(users))\nprint(\"Users:\", users)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:59:04.750124Z","iopub.execute_input":"2022-03-11T17:59:04.750405Z","iopub.status.idle":"2022-03-11T17:59:05.378235Z","shell.execute_reply.started":"2022-03-11T17:59:04.750378Z","shell.execute_reply":"2022-03-11T17:59:05.377394Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":" **2**","metadata":{}},{"cell_type":"code","source":"t_ini = time.time()# t1 is the initial time \n\n\n\ndata_f[\"User_Shift\"] = data_f[\"user\"].shift(1)\ndata_f[\"Class_Shift\"] = data_f[\"class\"].shift(1)\ndata_f['timestamp'] = pd.to_datetime(data_f['timestamp'])#in case if the time stamp is not uniform\ndata_f[\"Time_Shift\"] = data_f[\"timestamp\"].shift(1)#shift by 1 so that can be found change \n\ndata_f[\"is_user_shift\"] = (data_f[\"user\"]!=data_f[\"User_Shift\"])\ndata_f[\"is_class_shift\"] = (data_f[\"class\"]!=data_f[\"Class_Shift\"])\n\ndata_f[\"is_time_shift\"] = ((data_f[\"Time_Shift\"]-data_f[\"timestamp\"]).dt.total_seconds() > 10)#check whether the total number of seconds in given duration is > 10 \n\nclasses = [\"car\", \"train\", \"bus\", \"walk\", \"bike\", \"e-bike\"]\ncar, bus, walk, e_bike, bike, train, users_list, i = [], [], [], [], [], [], [], 1\n\nfor user in users:\n    users_data_f = data_f[data_f[\"user\"]==user].reset_index(drop=True)#by using drop we mean here to make the column as index and removed in the data frame automatically\n    users_list.append(user)\n    \n    d = {'bike': 0, 'car': 0, 'walk': 0, 'bus': 0, 'train': 0, 'e-bike': 0}\n    class_shift_points = users_data_f.loc[users_data_f[\"is_class_shift\"]==True]# loc: access a gp of rows and columns by labels or a boolean row\n    time_shift_points = users_data_f.loc[users_data_f[\"is_time_shift\"]==True]\n    dict1 = dict(class_shift_points[\"class\"].value_counts())#uniquely count the items in that column\n    dict2 = dict(time_shift_points[\"class\"].value_counts())\n    \n    for i in dict1.items():#The items() method returns a view object. The view object contains the key-value pairs of the dictionary, as tuples in a list.\n        d[i[0]] = d[i[0]] + i[1]\n    for i in dict2.items():\n        d[i[0]] = d[i[0]] + i[1]\n    \n    \n    e_bike.append(d['e-bike'])\n    bus.append(d['bus'])\n    car.append(d['car'])\n    train.append(d['train'])\n    walk.append(d['walk'])\n    bike.append(d['bike'])\n    \n    \nfinal_table = pd.DataFrame({\"user\":users_list, \"car\":car,\"bus\":bus,  \"e-bike\":e_bike,\"train\":train, \"bike\":bike, \"walk\":walk})\n\nt_fin = time.time()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:59:05.380786Z","iopub.execute_input":"2022-03-11T17:59:05.381222Z","iopub.status.idle":"2022-03-11T17:59:40.852577Z","shell.execute_reply.started":"2022-03-11T17:59:05.381179Z","shell.execute_reply":"2022-03-11T17:59:40.851357Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"Total time taken is : \",(t_fin-t_ini), \"seconds\") \n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:59:40.854925Z","iopub.execute_input":"2022-03-11T17:59:40.855385Z","iopub.status.idle":"2022-03-11T17:59:40.863126Z","shell.execute_reply.started":"2022-03-11T17:59:40.855327Z","shell.execute_reply":"2022-03-11T17:59:40.862335Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"final_table","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:59:40.864471Z","iopub.execute_input":"2022-03-11T17:59:40.865260Z","iopub.status.idle":"2022-03-11T17:59:40.887190Z","shell.execute_reply.started":"2022-03-11T17:59:40.865216Z","shell.execute_reply":"2022-03-11T17:59:40.886577Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**part-3**","metadata":{}},{"cell_type":"code","source":"t_ini = time.time()#initial time of the window\n\ndata_f[\"is_new_sequence\"] = (data_f[\"is_time_shift\"] + data_f[\"is_class_shift\"] + data_f[\"is_user_shift\"])\nSeq_num =[]\ncount = 0\n\nNew_Sequences = data_f.loc[data_f[\"is_new_sequence\"]==True]# loc: access a gp of rows and columns by labels or a boolean row\nindex = New_Sequences.index # making new_sequences a index\n\nfor i in range(len(index)-1):\n    seq_len = index[i+1]-index[i]\n    new_list = [i+1]*seq_len\n    Seq_num.append(new_list)\n    count = i+1\n    \nrem_len = len(data_f)-index[count]\n\nSeq_num.append([count+1]*rem_len)\n\nflattened_list = list(chain(*Seq_num))#flattening the list of a list like [1,[1,2]] after this [1,1,2]\nsequences = np.unique(flattened_list)# to fetch the unique value in a particular column\n\ndata_f[\"sequence_num\"] = flattened_list\nwin_time=[]\nseq_part_num = []\n\nfor seq in sequences:\n    seq_df = data_f[data_f[\"sequence_num\"]==seq].reset_index(drop=True)\n    min_time = seq_df[\"timestamp\"][0]\n    min_time_list = [min_time]*len(seq_df)\n    min_time_list = pd.to_datetime(min_time_list)#in case if the time stamp is not uniform\n    time_diff = (seq_df[\"timestamp\"]-min_time_list).dt.total_seconds()#counting total seconds\n    \n    window_num = np.floor_divide(time_diff,5)\n    window_to_str = window_num.apply(str)#apply() to Convert the Integers to Strings in Pandas DataFrame\n    seq_str = [str(seq)]*len(seq_df)\n    _str = [\"_\"]*len(seq_df)\n    part_num = list(i+j for i,j in zip(seq_str , _str))#making iterator of tuple through zip\n    part_num = list(i+j for i,j in zip(part_num , window_to_str))\n    \n    win_time.append(window_num)\n    seq_part_num.append(part_num)\n    \nwin_time = list(chain.from_iterable(win_time))\nseq_part_num = list(chain.from_iterable(seq_part_num))#flattening the list of a list like [1,[1,2]] after this [1,1,2]\ndata_f[\"Partition label\"] = seq_part_num\n\ndf1 = [y for x,y in data_f.groupby(data_f['class'])]#group the data using column 'class'\n\nclass_name=[]\nwindows_final = []\nfor class_grp in df1:\n    class_grp = class_grp.reset_index(drop=True)#by using drop we mean here to make the column as index and removed in the data frame automatically\n    Class = class_grp[\"class\"][0]\n    class_name.append(Class)\n    wind_count = len(class_grp[\"Partition label\"].unique())\n    windows_final.append(wind_count)\n    \nclass_wid_table = pd.DataFrame({\"Class Name\":class_name, \"5 second windows in Class\":windows_final})\n\nt_fin = time.time()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T17:59:40.888239Z","iopub.execute_input":"2022-03-11T17:59:40.888624Z","iopub.status.idle":"2022-03-11T18:00:39.184008Z","shell.execute_reply.started":"2022-03-11T17:59:40.888596Z","shell.execute_reply":"2022-03-11T18:00:39.183398Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(\"Total time taken for the window partition is: \", (t_fin-t_ini), \"seconds\")","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:00:39.185103Z","iopub.execute_input":"2022-03-11T18:00:39.185535Z","iopub.status.idle":"2022-03-11T18:00:39.190192Z","shell.execute_reply.started":"2022-03-11T18:00:39.185488Z","shell.execute_reply":"2022-03-11T18:00:39.189322Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**********","metadata":{}},{"cell_type":"markdown","source":"**4**","metadata":{}},{"cell_type":"code","source":"labels = data_f[\"Partition label\"].unique()#find the unique values of the column partition label\nprint(\"Total 5 second time window: \",len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:00:39.191348Z","iopub.execute_input":"2022-03-11T18:00:39.191595Z","iopub.status.idle":"2022-03-11T18:00:39.689685Z","shell.execute_reply.started":"2022-03-11T18:00:39.191562Z","shell.execute_reply":"2022-03-11T18:00:39.688884Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"label_dfs = [y for x,y in data_f.groupby(data_f['Partition label'])]#groupby using column Partition label \nlabel = []\nlabel_class = []\nfeatures = []\n\nfor label_df in label_dfs:\n    label_df = label_df.reset_index(drop=True)#by using drop we mean here to make the column as index and removed in the data frame automatically\n    \n    label.append(label_df[\"Partition label\"][0])\n    label_class.append(label_df[\"class\"][0])\n    \n    x_min = min(label_df[\"x\"])\n    y_min = min(label_df[\"y\"])\n    z_min = min(label_df[\"z\"])\n    \n    x_max = max(label_df[\"x\"])\n    y_max = max(label_df[\"y\"])\n    z_max = max(label_df[\"z\"])\n    \n    x_avg = np.mean(label_df[\"x\"])\n    y_avg = np.mean(label_df[\"y\"])\n    z_avg = np.mean(label_df[\"z\"])\n    \n    x_std = np.std(label_df[\"x\"])\n    y_std = np.std(label_df[\"y\"])\n    z_std = np.std(label_df[\"z\"])\n    \n    features.append([x_min, y_min, z_min, x_max, y_max, z_max, x_avg, y_avg, z_avg, x_std, y_std, z_std])\n    \nfeature_columns = [\"x_min\", \"y_min\", \"z_min\", \"x_max\", \"y_max\", \"z_max\", \n                   \"x_avg\", \"y_avg\", \"z_avg\", \"x_std\", \"y_std\", \"z_std\"]\n    \nfeatures = pd.DataFrame(features, columns = feature_columns)\nfeatures[\"Label\"] = label\nfeatures[\"class\"] = label_class\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:00:39.690765Z","iopub.execute_input":"2022-03-11T18:00:39.691067Z","iopub.status.idle":"2022-03-11T18:01:19.737948Z","shell.execute_reply.started":"2022-03-11T18:00:39.691037Z","shell.execute_reply":"2022-03-11T18:01:19.737178Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:19.740535Z","iopub.execute_input":"2022-03-11T18:01:19.740833Z","iopub.status.idle":"2022-03-11T18:01:19.761569Z","shell.execute_reply.started":"2022-03-11T18:01:19.740802Z","shell.execute_reply":"2022-03-11T18:01:19.760598Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=3, figsize=(20,20))\n\nsns.boxplot(x='class', y='x_min', data=features, ax=ax[0][0])\nsns.boxplot(x='class', y='y_min', data=features, ax=ax[0][1])\nsns.boxplot(x='class', y='z_min', data=features, ax=ax[0][2])\nsns.boxplot(x='class', y='x_max', data=features, ax=ax[1][0])\nsns.boxplot(x='class', y='y_max', data=features, ax=ax[1][1])\nsns.boxplot(x='class', y='z_max', data=features, ax=ax[1][2])\nsns.boxplot(x='class', y='x_avg', data=features, ax=ax[2][0])\nsns.boxplot(x='class', y='y_avg', data=features, ax=ax[2][1])\nsns.boxplot(x='class', y='z_avg', data=features, ax=ax[2][2])\nsns.boxplot(x='class', y='x_std', data=features, ax=ax[3][0])\nsns.boxplot(x='class', y='y_std', data=features, ax=ax[3][1])\nsns.boxplot(x='class', y='z_std', data=features, ax=ax[3][2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:19.763089Z","iopub.execute_input":"2022-03-11T18:01:19.763457Z","iopub.status.idle":"2022-03-11T18:01:22.221100Z","shell.execute_reply.started":"2022-03-11T18:01:19.763420Z","shell.execute_reply":"2022-03-11T18:01:22.220317Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**part-5**","metadata":{}},{"cell_type":"code","source":"balanced_dataset = pd.DataFrame()\nmin_widws = min(features[\"class\"].value_counts())\n\nfor Class in classes:\n    class_df = features[features[\"class\"]==Class].reset_index(drop=True)\n    class_df = class_df.sample(n=min_widws)\n    balanced_dataset = balanced_dataset.append(class_df, ignore_index=True)\n\nbalanced_dataset = balanced_dataset.sample(frac=1).reset_index()#sample: The frac keyword argument specifies the fraction of rows to return in the random sample, so frac=1 means return all rows (in random order).","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:22.222458Z","iopub.execute_input":"2022-03-11T18:01:22.223215Z","iopub.status.idle":"2022-03-11T18:01:22.298115Z","shell.execute_reply.started":"2022-03-11T18:01:22.223178Z","shell.execute_reply":"2022-03-11T18:01:22.297521Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(\"Class & Data_points\")\nbalanced_dataset[\"class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:22.299405Z","iopub.execute_input":"2022-03-11T18:01:22.299774Z","iopub.status.idle":"2022-03-11T18:01:22.307094Z","shell.execute_reply.started":"2022-03-11T18:01:22.299747Z","shell.execute_reply":"2022-03-11T18:01:22.306538Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**part-6**","metadata":{}},{"cell_type":"code","source":"\ntrain_df = balanced_dataset.sample(frac=0.6)\ntest_val = balanced_dataset.drop(train_df.index)\nval_df = test_val.sample(frac=0.5)\ntest_df = test_val.drop(val_df.index)\n\ntrain_df = train_df.reset_index()\nval_df = val_df.reset_index()\ntest_df = test_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:22.308506Z","iopub.execute_input":"2022-03-11T18:01:22.308925Z","iopub.status.idle":"2022-03-11T18:01:22.320092Z","shell.execute_reply.started":"2022-03-11T18:01:22.308886Z","shell.execute_reply":"2022-03-11T18:01:22.319447Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(\"Num of Data Points in Training Data: \", len(train_df))\nprint(\"Num of Data Points in Validation Data: \", len(val_df))\nprint(\"Num of Data Points in Test Data: \", len(test_df))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:22.321561Z","iopub.execute_input":"2022-03-11T18:01:22.321925Z","iopub.status.idle":"2022-03-11T18:01:22.327040Z","shell.execute_reply.started":"2022-03-11T18:01:22.321884Z","shell.execute_reply":"2022-03-11T18:01:22.326293Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**part-7**","metadata":{}},{"cell_type":"markdown","source":"**SVM**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Perceptron, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import datasets\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:01:22.328235Z","iopub.execute_input":"2022-03-11T18:01:22.329012Z","iopub.status.idle":"2022-03-11T18:01:22.461426Z","shell.execute_reply.started":"2022-03-11T18:01:22.328981Z","shell.execute_reply":"2022-03-11T18:01:22.460411Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:03:24.352396Z","iopub.execute_input":"2022-03-11T18:03:24.352701Z","iopub.status.idle":"2022-03-11T18:03:24.376527Z","shell.execute_reply.started":"2022-03-11T18:03:24.352672Z","shell.execute_reply":"2022-03-11T18:03:24.375716Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"X_train = train_df[['level_0','x_min','y_min','z_min','x_max','z_max','x_avg','y_avg','z_avg','x_std','y_std','z_std']]\nX_test=test_df[['level_0','x_min','y_min','z_min','x_max','z_max','x_avg','y_avg','z_avg','x_std','y_std','z_std']]\ny_train= train_df[['class']]\ny_test= test_df[['class']]\n \n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:07:26.895704Z","iopub.execute_input":"2022-03-11T18:07:26.896096Z","iopub.status.idle":"2022-03-11T18:07:26.904243Z","shell.execute_reply.started":"2022-03-11T18:07:26.896069Z","shell.execute_reply":"2022-03-11T18:07:26.903322Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nclf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\nclf.fit(X_train,y_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:07:46.249100Z","iopub.execute_input":"2022-03-11T18:07:46.249392Z","iopub.status.idle":"2022-03-11T18:07:46.282899Z","shell.execute_reply.started":"2022-03-11T18:07:46.249362Z","shell.execute_reply":"2022-03-11T18:07:46.281935Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:08:50.408638Z","iopub.execute_input":"2022-03-11T18:08:50.409398Z","iopub.status.idle":"2022-03-11T18:08:50.420736Z","shell.execute_reply.started":"2022-03-11T18:08:50.409360Z","shell.execute_reply":"2022-03-11T18:08:50.420131Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"clf.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:09:38.077212Z","iopub.execute_input":"2022-03-11T18:09:38.078122Z","iopub.status.idle":"2022-03-11T18:09:38.090013Z","shell.execute_reply.started":"2022-03-11T18:09:38.078078Z","shell.execute_reply":"2022-03-11T18:09:38.089206Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**LR**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf1= LogisticRegression(random_state=0).fit(X_train, y_train)\nclf1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:15:08.664975Z","iopub.execute_input":"2022-03-11T18:15:08.665309Z","iopub.status.idle":"2022-03-11T18:15:08.740684Z","shell.execute_reply.started":"2022-03-11T18:15:08.665251Z","shell.execute_reply":"2022-03-11T18:15:08.739824Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"clf1.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:15:28.419853Z","iopub.execute_input":"2022-03-11T18:15:28.420144Z","iopub.status.idle":"2022-03-11T18:15:28.428001Z","shell.execute_reply.started":"2022-03-11T18:15:28.420103Z","shell.execute_reply":"2022-03-11T18:15:28.427445Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"***ANN*","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nclf3 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n                   hidden_layer_sizes=(5, 2), random_state=1)\nclf3.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:21:00.013358Z","iopub.execute_input":"2022-03-11T18:21:00.014104Z","iopub.status.idle":"2022-03-11T18:21:00.183879Z","shell.execute_reply.started":"2022-03-11T18:21:00.014056Z","shell.execute_reply":"2022-03-11T18:21:00.182968Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"clf3.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:21:03.100154Z","iopub.execute_input":"2022-03-11T18:21:03.101092Z","iopub.status.idle":"2022-03-11T18:21:03.109256Z","shell.execute_reply.started":"2022-03-11T18:21:03.101004Z","shell.execute_reply":"2022-03-11T18:21:03.108581Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"clf3.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T18:21:06.436245Z","iopub.execute_input":"2022-03-11T18:21:06.436568Z","iopub.status.idle":"2022-03-11T18:21:06.446340Z","shell.execute_reply.started":"2022-03-11T18:21:06.436529Z","shell.execute_reply":"2022-03-11T18:21:06.445408Z"},"trusted":true},"execution_count":43,"outputs":[]}]}